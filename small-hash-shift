From: L. David Baron <dbaron@dbaron.org>

Keep PLDHashTable's second hash small to reduce the size of jumps across memory and improve cache behavior.

PLDHashTable takes the result of the hash function and multiplies it by
kGoldenRatio to ensure that it has a good distribution of bits across
the 32-bit hash value, and then zeroes out the low bit so that it can be
used for the collision flag.  This result is called hash0.  From hash0
it computes two different numbers used to find entries in the table
storage:  hash1 is used to find an initial position in the table to
begin searching for an entry; hash2 is then used to repeatedly offset
that position (mod the size of the table) to build a chain of positions
to search.

In a table with capacity 2^c entries, hash1 is simply the upper c bits
of hash0.  This patch does not change this.

Prior to this patch (but only since bug NNNNNNN), hash2 was the low c
bits of hash0.  This manner of computing hash2 is problematic because
chain can jump across very large areas of memory in a way that is
unfriendly to CPU caches.

So this patch changes the hash2 computation by capping the size of hash2
to try to make it more cache-friendly.

TODO: Measure to find an optimal value of kHash2MaskMaxBits, or whether
we should have a maximum at all!


MozReview-Commit-ID: 7FgybeBgjLF

diff --git a/xpcom/ds/PLDHashTable.cpp b/xpcom/ds/PLDHashTable.cpp
--- a/xpcom/ds/PLDHashTable.cpp
+++ b/xpcom/ds/PLDHashTable.cpp
@@ -263,22 +263,33 @@ PLDHashTable::Hash2(PLDHashNumber aHash0
 
   // The incoming aHash0 always has the low bit unset (since we leave it
   // free for the collision flag), and should have reasonably random
   // data in the other 31 bits.  We used the high bits of aHash0 for
   // Hash1, so we use the low bits here.  If the table size is large,
   // the bits we use may overlap, but that's still more random than
   // filling with 0s.
   //
+  // Since the result of Hash2 controls how far we jump around the table
+  // to build a chain after starting at a location determined by Hash1,
+  // we'd like to keep it small, to improve cache behavior.
+  // Keep the jumps from the second hash small, to improve cache behavior.
+  const uint32_t kHash2MaskMaxBits = 6;
+  uint32_t hash2Mask;
+  if (sizeLog2 >= kHash2MaskMaxBits) {
+    hash2Mask = (PLDHashNumber(1) << kHash2MaskMaxBits) - 1;
+  } else {
+    hash2Mask = sizeMask;
+  }
   // Double hashing needs the second hash code to be relatively prime to table
   // size, so we simply make hash2 odd.
   //
   // This also conveniently covers up the fact that we have the low bit
   // unset since aHash0 has the low bit unset.
-  aHash2Out = (aHash0 & sizeMask) | 1;
+  aHash2Out = (aHash0 & hash2Mask) | 1;
 }
 
 // Reserve mKeyHash 0 for free entries and 1 for removed-entry sentinels. Note
 // that a removed-entry sentinel need be stored only if the removed entry had
 // a colliding entry added after it. Therefore we can use 1 as the collision
 // flag in addition to the removed-entry sentinel value. Multiplicative hash
 // uses the high order bits of mKeyHash, so this least-significant reservation
 // should not hurt the hash function's effectiveness much.
